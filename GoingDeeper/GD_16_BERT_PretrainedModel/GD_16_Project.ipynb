{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GD_16_Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be2460555d0544fdb2e6f716998d9128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59046b7801f84895953a4840a0d2a4d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f1f4a448edf4ea19d63faaef57277a4",
              "IPY_MODEL_b50bb9162557485aa0965be6bfc7635f"
            ]
          }
        },
        "59046b7801f84895953a4840a0d2a4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f1f4a448edf4ea19d63faaef57277a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5126319cc4844647b0668d832b5e9769",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3957761,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3957761,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afcd81eb59ad44cba140bf599013d002"
          }
        },
        "b50bb9162557485aa0965be6bfc7635f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b97f554e16af4603acf74d1d75be1a2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3957761/3957761 [06:15&lt;00:00, 10536.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c754db1296744fdd9b14c0236abaa43e"
          }
        },
        "5126319cc4844647b0668d832b5e9769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afcd81eb59ad44cba140bf599013d002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b97f554e16af4603acf74d1d75be1a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c754db1296744fdd9b14c0236abaa43e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc11eb8de7b948de9986870a6bad9de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a30d7f16b9f439aa125f2dbe909b58f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7733065854b84cd483708b81405bae31",
              "IPY_MODEL_18aaa9b224af4118a17b7dee8b8b31f2"
            ]
          }
        },
        "9a30d7f16b9f439aa125f2dbe909b58f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7733065854b84cd483708b81405bae31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_529ec179330e49339bbdf9cd164da1ff",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 918189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41abae2c6ad344ec881d67d9fbbbc58e"
          }
        },
        "18aaa9b224af4118a17b7dee8b8b31f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a219c1cbbb5147c080fcec2cc44d0ee0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/918189 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66e60b4646024c3c83dfe98a4fc7e4c7"
          }
        },
        "529ec179330e49339bbdf9cd164da1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41abae2c6ad344ec881d67d9fbbbc58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a219c1cbbb5147c080fcec2cc44d0ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66e60b4646024c3c83dfe98a4fc7e4c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fd8d329d2d54a558343e7d3e557ced4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c927d0887034dfb8fe5afde7b7568a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93b2e020e00247db9e8c53c8b6ce1055",
              "IPY_MODEL_cea0f3a0229849d28f7bb580f4e1fda7"
            ]
          }
        },
        "1c927d0887034dfb8fe5afde7b7568a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93b2e020e00247db9e8c53c8b6ce1055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21de7b2409d445f9adf06949e624bc3b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 128000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 127909,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ca3cb7da39345e28902164652159c57"
          }
        },
        "cea0f3a0229849d28f7bb580f4e1fda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_af4b3f1de82744e3888ae8750b45160b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 127909/128000 [00:48&lt;00:00, 4436.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1d270bbe9dd4e00bfc089fc7bd8cf47"
          }
        },
        "21de7b2409d445f9adf06949e624bc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ca3cb7da39345e28902164652159c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af4b3f1de82744e3888ae8750b45160b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1d270bbe9dd4e00bfc089fc7bd8cf47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGn7-jWktdTQ",
        "outputId": "a2dab20d-4c1e-467b-ef68-38d3c6a13dd1"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g3nLcUstujA",
        "outputId": "44d35704-ad09-4632-d049-de0d81b2764f"
      },
      "source": [
        "# imports\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import collections\n",
        "import json\n",
        "import shutil\n",
        "import zipfile\n",
        "import copy\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sentencepiece as spm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "random_seed = 1234\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# tf version 및 gpu 확인\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFJo25sht0Gk",
        "outputId": "96842580-5248-4671-ec5e-5ed1b1dec000"
      },
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "# corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
        "base_path = '/content/drive/MyDrive/DL_Study/AIFFEL/19_Bert/'\n",
        "corpus_file = base_path + 'data/kowiki.txt'\n",
        "\n",
        "prefix = 'ko_8000'\n",
        "vocab_size = 8000\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "    f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
        "    \" --model_type=bpe\" +\n",
        "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
        "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
        "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
        "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
        "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
        "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰\n",
        "\n",
        "print(\"완료=3\")   # 완료메시지가 출력될 때까지 아무 출력내용이 없더라도 기다려 주세요."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "완료=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGqM6sJquJd0",
        "outputId": "30fb2800-add7-4561-e7f9-87cc4bd74712"
      },
      "source": [
        "data_dir = base_path\n",
        "model_dir = base_path+'/models'\n",
        "\n",
        "# vocab loading\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(f\"./ko_8000.model\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpEdntRTvz6X"
      },
      "source": [
        "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
        "    \"\"\"\n",
        "    마스크 생성\n",
        "    :param tokens: tokens\n",
        "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
        "    :param vocab_list: vocab list (random token 용)\n",
        "    :return tokens: mask된 tokens\n",
        "    :return mask_idx: mask된 token의 index\n",
        "    :return mask_label: mask된 token의 원래 값\n",
        "    \"\"\"\n",
        "    # 단어 단위로 mask 하기 위해서 index 분할\n",
        "    cand_idx = []  # word 단위의 index array\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[-1].append(i)\n",
        "        else:\n",
        "            cand_idx.append([i])\n",
        "    # random mask를 위해서 순서를 섞음\n",
        "    random.shuffle(cand_idx)\n",
        "\n",
        "    mask_lms = []  # mask 된 값\n",
        "    for index_set in cand_idx:\n",
        "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
        "            break\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
        "            continue\n",
        "        dice = random.random()  # 0..1 사이의 확률 값\n",
        "        for index in index_set:\n",
        "            masked_token = None\n",
        "            if dice < 0.8:  # 80% replace with [MASK]\n",
        "                masked_token = \"[MASK]\"\n",
        "            elif dice < 0.9: # 10% keep original\n",
        "                masked_token = tokens[index]\n",
        "            else:  # 10% random word\n",
        "                masked_token = random.choice(vocab_list)\n",
        "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "            tokens[index] = masked_token\n",
        "    # mask_lms 정렬 후 mask_idx, mask_label 추출\n",
        "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "    mask_idx = [p[\"index\"] for p in mask_lms]  # mask된 token의 index\n",
        "    mask_label = [p[\"label\"] for p in mask_lms]  # mask된 token의 원래 값\n",
        "\n",
        "    return tokens, mask_idx, mask_label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZJO5K7cxHh5"
      },
      "source": [
        "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
        "    \"\"\"\n",
        "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
        "    :param tokens_a: tokens A\n",
        "    :param tokens_b: tokens B\n",
        "    :param max_seq: 두 tokens 길이의 최대 값\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_seq:\n",
        "            break\n",
        "\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            del tokens_a[0]\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVabhwXg1nKf"
      },
      "source": [
        "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
        "    \"\"\"\n",
        "    doc별 pretrain 데이터 생성\n",
        "    \"\"\"\n",
        "    # for CLS], [SEP], [SEP]\n",
        "    max_seq = n_seq - 3\n",
        "\n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i])  # line\n",
        "        current_length += len(doc[i])\n",
        "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
        "            # token a\n",
        "            a_end = 1\n",
        "            if 1 < len(current_chunk):\n",
        "                a_end = random.randrange(1, len(current_chunk))\n",
        "            tokens_a = []\n",
        "            for j in range(a_end):\n",
        "                tokens_a.extend(current_chunk[j])\n",
        "            # token b\n",
        "            tokens_b = []\n",
        "            for j in range(a_end, len(current_chunk)):\n",
        "                tokens_b.extend(current_chunk[j])\n",
        "\n",
        "            if random.random() < 0.5:  # 50% 확률로 swap\n",
        "                is_next = 0\n",
        "                tokens_t = tokens_a\n",
        "                tokens_a = tokens_b\n",
        "                tokens_b = tokens_t\n",
        "            else:\n",
        "                is_next = 1\n",
        "            # max_seq 보다 큰 경우 길이 조절\n",
        "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "            assert 0 < len(tokens_a)\n",
        "            assert 0 < len(tokens_b)\n",
        "            # tokens & aegment 생성\n",
        "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "            # mask\n",
        "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "            instance = {\n",
        "                \"tokens\": tokens,\n",
        "                \"segment\": segment,\n",
        "                \"is_next\": is_next,\n",
        "                \"mask_idx\": mask_idx,\n",
        "                \"mask_label\": mask_label\n",
        "            }\n",
        "            instances.append(instance)\n",
        "\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV3o35h41uxP",
        "outputId": "76d93558-63b8-4669-e2a3-8dccc6c0c46c"
      },
      "source": [
        "total = 0\n",
        "with open(corpus_file, 'r') as in_f:\n",
        "    for line in in_f:\n",
        "        total += 1\n",
        "\n",
        "total"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3957761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEXcPokl1y5Q"
      },
      "source": [
        "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
        "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
        "    def save_pretrain_instances(out_f, doc):\n",
        "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
        "        for instance in instances:\n",
        "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
        "            out_f.write(\"\\n\")\n",
        "\n",
        "    # 특수문자 7개를 제외한 vocab_list 생성\n",
        "    vocab_list = []\n",
        "    for id in range(7, len(vocab)):\n",
        "        if not vocab.is_unknown(id):\n",
        "            vocab_list.append(vocab.id_to_piece(id))\n",
        "\n",
        "    # line count 확인\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        with open(out_file, \"w\") as out_f:\n",
        "            doc = []\n",
        "            for line in tqdm(in_f, total=line_cnt):\n",
        "                line = line.strip()\n",
        "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락을 의미 함)\n",
        "                    if 0 < len(doc):\n",
        "                        save_pretrain_instances(out_f, doc)\n",
        "                        doc = []\n",
        "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
        "                save_pretrain_instances(out_f, doc)\n",
        "                doc = []"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "be2460555d0544fdb2e6f716998d9128",
            "59046b7801f84895953a4840a0d2a4d2",
            "5f1f4a448edf4ea19d63faaef57277a4",
            "b50bb9162557485aa0965be6bfc7635f",
            "5126319cc4844647b0668d832b5e9769",
            "afcd81eb59ad44cba140bf599013d002",
            "b97f554e16af4603acf74d1d75be1a2d",
            "c754db1296744fdd9b14c0236abaa43e"
          ]
        },
        "id": "xAQeRtv219M_",
        "outputId": "b504e090-e200-41a9-8730-680b64f0c802"
      },
      "source": [
        "pretrain_json_path = base_path+'data/bert_pre_train.json'\n",
        "\n",
        "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be2460555d0544fdb2e6f716998d9128",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3957761.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EnWCDUM2Am9",
        "outputId": "8fea9f39-0597-4d4e-b364-533439045541"
      },
      "source": [
        "# 라인수\n",
        "total = 0\n",
        "with open(pretrain_json_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        total += 1\n",
        "total"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "918189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ3kWYTO2FfL",
        "outputId": "4df4c01f-e64a-4455-d2b3-4bf2f75e364d"
      },
      "source": [
        "n_seq = 128\n",
        "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
        "max_seq = n_seq - 3\n",
        "\n",
        "# 만약 일반적인 Numpy Array에다 데이터를 로딩한다면 이렇게 되겠지만\n",
        "# enc_tokens = np.zeros((total, n_seq), np.int32)\n",
        "# dec_tokens = np.zeros((total, n_seq), np.int32)\n",
        "# labels_nsp = np.zeros((total,), np.int32)\n",
        "# labels_mlm = np.zeros((total, n_seq), np.int32)\n",
        "\n",
        "# np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
        "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
        "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "\n",
        "\n",
        "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " 0,\n",
              " 0,\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dc11eb8de7b948de9986870a6bad9de0",
            "9a30d7f16b9f439aa125f2dbe909b58f",
            "7733065854b84cd483708b81405bae31",
            "18aaa9b224af4118a17b7dee8b8b31f2",
            "529ec179330e49339bbdf9cd164da1ff",
            "41abae2c6ad344ec881d67d9fbbbc58e",
            "a219c1cbbb5147c080fcec2cc44d0ee0",
            "66e60b4646024c3c83dfe98a4fc7e4c7"
          ]
        },
        "id": "gANMiPWv2Hse",
        "outputId": "31ee21be-fccf-4028-bc82-831bc64328a2"
      },
      "source": [
        "# 라인 단위로 처리\n",
        "with open(pretrain_json_path, \"r\") as f:\n",
        "    for i, line in enumerate(tqdm(f, total=total)):\n",
        "        if 5 < i:  # 테스트를 위해서 5개만 확인\n",
        "            break\n",
        "        data = json.loads(line)\n",
        "        # encoder token\n",
        "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
        "        enc_token += [0] * (n_seq - len(enc_token))\n",
        "        # segment\n",
        "        segment = data[\"segment\"]\n",
        "        segment += [0] * (n_seq - len(segment))\n",
        "        # nsp label\n",
        "        label_nsp = data[\"is_next\"]\n",
        "        # mlm label\n",
        "        mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
        "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
        "        label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
        "        label_mlm[mask_idx] = mask_label\n",
        "\n",
        "        print(data)\n",
        "        print(\"enc_token:\", enc_token)\n",
        "        print(\"segment:\", segment)\n",
        "        print(\"label_nsp:\", label_nsp)\n",
        "        print(\"label_mlm:\", label_mlm)\n",
        "        print()\n",
        "\n",
        "        assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
        "\n",
        "        enc_tokens[i] = enc_token\n",
        "        segments[i] = segment\n",
        "        labels_nsp[i] = label_nsp\n",
        "        labels_mlm[i] = label_mlm\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc11eb8de7b948de9986870a6bad9de0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=918189.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'tokens': ['[CLS]', '에서', '▁태어났다', '.', '▁조지', '아', '▁공', '과', '대학교', '를', '▁졸업', '하였다', '.', '▁그', '▁후', '▁해', '군에', '▁들어가', '▁전', '함', '·', '원', '자', '력', '·', '잠', '수', '함', '의', '▁승', '무', '원으로', '▁일', '하였다', '.', '[MASK]', '[MASK]', '[MASK]', '鬼', '▁해군', '▁대', '위로', '▁예', '편', '하였고', '▁이후', '▁땅', '콩', '·', '면', '화', '▁등을', '▁가', '꿔', '▁많은', '▁돈', '을', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁\"', '땅', '콩', '▁농', '부', '\"', '▁(', 'P', 'e', 'an', 'ut', '▁F', 'ar', 'm', 'er', ')', '로', '▁알려', '졌다', '.', '[SEP]', '[MASK]', '[MASK]', '▁카', '터', '[MASK]', '▁얼', '▁\"', '지', '미', '\"', '[MASK]', '[MASK]', '▁주', '니어', '(,', '▁192', '4', '년', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주', '당', '▁출신', '▁미국', '[MASK]', '[MASK]', '[MASK]', '▁대통령', '▁(19', '7', '7', '년', '▁~', '▁1981', '년', ')', '이다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [35, 36, 37, 38, 57, 58, 59, 60, 61, 62, 84, 85, 88, 94, 95, 113, 114, 115], 'mask_label': ['▁195', '3', '년', '▁미국', '▁벌', '었다', '.', '▁그의', '▁별', '명이', '▁지', '미', '▁제임스', '▁카', '터', '▁3', '9', '번째']}\n",
            "enc_token: [5, 10, 1605, 3599, 1755, 3630, 41, 3644, 830, 3624, 1135, 52, 3599, 13, 81, 87, 1501, 2247, 25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636, 3779, 3601, 249, 3725, 1232, 33, 52, 3599, 6, 6, 6, 6322, 2780, 14, 1509, 168, 3877, 414, 165, 1697, 4290, 3873, 3703, 3683, 593, 21, 5007, 399, 1927, 3607, 6, 6, 6, 6, 6, 6, 103, 4313, 4290, 613, 3638, 3718, 98, 3878, 3656, 256, 2543, 309, 337, 3735, 181, 3616, 3603, 489, 376, 3599, 4, 6, 6, 207, 3714, 6, 1042, 103, 3610, 3686, 3718, 6, 6, 37, 3418, 416, 810, 3666, 3625, 131, 3662, 7, 3629, 203, 241, 3602, 1114, 3724, 788, 243, 6, 6, 6, 663, 1647, 3682, 3682, 3625, 203, 3008, 3625, 3616, 16, 3599, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 0\n",
            "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0  479 3652 3625  243    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0  813   17 3599  307  587  931    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   18 3686    0    0 3324    0    0    0    0    0  207 3714    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0   49 3632  796    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', '[MASK]', '▁주', '▁상', '원', '▁의원', '▁선거', '에서', '▁낙', '선', '하나', '[MASK]', '▁선거', '가', '▁부정', '선거', '▁', '였', '음을', '▁입', '증', '하게', '▁되어', '[MASK]', '[MASK]', '[MASK]', '▁196', '6', '년', '▁조지', '아', '[MASK]', '▁지', '사', '▁선거', '에', '▁낙', '선', '하지만', '▁1970', '년', '▁조지', '아', '▁주', '▁지', '사를', '▁역임', '했다', '.', '▁대통령', '이', '[MASK]', '[MASK]', '▁전', '▁조지', '아', '주', '▁상', '원의', '원을', '▁두', '번', '▁연', '임', '했으며', ',', '▁1971', '년부터', '[MASK]', '[MASK]', '▁조지', '아', '▁지', '사로', '[MASK]', '[MASK]', '[MASK]', '▁조지', '아', '[MASK]', '[MASK]', '[MASK]', '▁지', '내', '면서', ',', '▁미국', '에', '▁사는', '▁흑', '인', '▁등', '용', '법을', '▁내', '세', '웠다', '.', '[SEP]', '▁1976', '년', '▁대통령', '[MASK]', '[MASK]', '▁민주', '당', '▁후보', '로', '▁출', '마', '하여', '▁도', '덕', '주의', '▁정책', '으로', '▁내', '세', '워', ',', '▁포', '드를', '▁누', '르고', '▁당선', '되었다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 11, 23, 24, 25, 31, 51, 52, 68, 69, 74, 75, 76, 79, 80, 81, 102, 103], 'mask_label': ['아', '▁그', '▁당선', '되고', ',', '▁주', '▁되', '기', '▁1975', '년까지', '▁근무', '했다', '.', '▁주', '지', '사로', '▁선거', '에']}\n",
            "enc_token: [5, 6, 37, 76, 3667, 2378, 822, 10, 1567, 3668, 3294, 6, 822, 3608, 2386, 2163, 3596, 3671, 969, 213, 3929, 173, 607, 6, 6, 6, 386, 3673, 3625, 1755, 3630, 6, 18, 3620, 822, 3600, 1567, 3668, 1447, 1921, 3625, 1755, 3630, 37, 18, 451, 1398, 31, 3599, 663, 3597, 6, 6, 25, 1755, 3630, 3646, 76, 955, 928, 157, 3821, 61, 3773, 530, 3604, 3372, 523, 6, 6, 1755, 3630, 18, 982, 6, 6, 6, 1755, 3630, 6, 6, 6, 18, 3754, 151, 3604, 243, 3600, 3554, 1733, 3628, 50, 3717, 2046, 114, 3692, 1853, 3599, 4, 3306, 3625, 663, 6, 6, 1114, 3724, 958, 3603, 117, 3674, 54, 75, 4089, 238, 1421, 9, 114, 3692, 3964, 3604, 119, 1486, 807, 2056, 2387, 43, 3599, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 1\n",
            "label_mlm: [   0 3630    0    0    0    0    0    0    0    0    0   13    0    0\n",
            "    0    0    0    0    0    0    0    0    0 2387  317 3604    0    0\n",
            "    0    0    0   37    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0  450 3614    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0 3409  673\n",
            "    0    0    0    0 2711   31 3599    0    0   37 3610  982    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0  822 3600    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', ',', '▁캠', '프', '▁데이', '비', '드에서', '▁안', '와', '르', '▁사', '다', '트', '▁대통령', '과', '▁메', '나', '헴', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁함께', '▁중', '동', '▁평', '화를', '▁위한', '▁캠', '프', '데', '이', '비', '드', '▁협', '정을', '▁체결', '했다', '.', '▁그러나', '▁이것은', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁미국의', '▁유대', '인', '斬', '冕', '▁반', '발', '을', '▁일으', '켰', '다', '.', '▁1979', '년', '▁백', '악', '관', '에서', '▁양', '국', '▁간의', '▁평화', '조', '약', '으로', '▁이끌', '어졌다', '.', '▁또한', '[MASK]', '[MASK]', '▁제', '2', '차', '[MASK]', '▁무', '기', '▁제한', '[MASK]', '[MASK]', '▁조', '인', '했다', '.', '[SEP]', '▁카', '터', '는', '▁1970', '년대', '▁후반', '▁당시', '▁대한민국', '▁등', '▁인', '권', '▁후', '진', '국의', '[MASK]', '[MASK]', '▁인', '권을', '▁지', '키', '기', '▁위해', '▁노력', '했으며', ',', '▁취임', '[MASK]', '▁계속', '해서', '▁도', '덕', '정', '치를', '▁내', '세', '웠다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [18, 19, 20, 21, 41, 42, 43, 44, 48, 49, 74, 75, 79, 83, 84, 104, 105, 116], 'mask_label': ['▁베', '긴', '▁수상', '과', '▁공', '화', '당', '과', '▁단', '체의', '▁소련', '과', '▁전략', '▁협', '상에', '▁국민', '들의', '▁이후']}\n",
            "enc_token: [5, 3604, 2432, 3721, 965, 3694, 3552, 172, 3665, 3699, 15, 3598, 3677, 663, 3644, 334, 3637, 5887, 6, 6, 6, 6, 280, 35, 3658, 232, 934, 521, 2432, 3721, 3736, 3597, 3694, 3681, 617, 666, 2525, 31, 3599, 330, 1487, 6, 6, 6, 6, 679, 2670, 3628, 7504, 7871, 141, 3720, 3607, 1213, 4174, 3598, 3599, 2995, 3625, 456, 3928, 3708, 10, 230, 3643, 2714, 2793, 3676, 3827, 9, 1435, 2521, 3599, 276, 6, 6, 30, 3619, 3751, 6, 107, 3614, 1956, 6, 6, 53, 3628, 31, 3599, 4, 207, 3714, 3602, 1921, 596, 1840, 316, 410, 50, 42, 3830, 81, 3713, 137, 6, 6, 42, 917, 18, 3793, 3614, 231, 3375, 530, 3604, 2659, 6, 785, 874, 75, 4089, 3642, 1233, 114, 3692, 1853, 3599, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 1\n",
            "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0  271 4099 1011 3644    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0   41\n",
            " 3683 3724 3644    0    0    0  164 1314    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0 1302 3644    0    0    0 2835    0    0    0  617\n",
            " 1824    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0  968  247    0    0    0    0    0    0\n",
            "    0    0    0    0  165    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', '▁반', '대에', '▁부', '딪', '혀', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁완', '전', '철', '수', '▁대신', '▁6', ',000', '명을', '▁감', '축', '하는', '▁데', '[MASK]', '[MASK]', '[MASK]', '▁또한', '▁박', '정', '희', '▁정', '권의', '▁인', '권', '▁문제', '▁등', '과의', '▁논란', '으로', '▁불', '협', '화', '음을', '▁', '냈', '으나', ',', '▁1979', '년', '▁6', '월', '▁하', '순', ',', '▁대한민국', '을', '▁방문', '하여', '꾼', '▁기념', '▁다', '소', '▁회복', '되었다', '.', '[SEP]', '[MASK]', '▁주', '▁이란', '▁미국', '▁대사', '관', '▁인', '질', '▁사건', '에서', '▁인', '질', '▁구', '출', '▁실패', '를', '▁이유로', '▁1980', '년', '[MASK]', '▁선거', '에서', '▁공', '화', '당의', '▁로', '널', '드', '▁레이', '건', '▁후보', '에게', '▁', '져', '▁결국', '[MASK]', '[MASK]', '▁실패', '했다', '.', 'え', '[MASK]', '[MASK]', '▁말', '기에', '[MASK]', '[MASK]', '▁소련', '의', '▁아', '프가', '니', '스탄', '▁침공', '▁사건', '으로', '▁인해', '▁1980', '년', '▁하계', '▁올림픽', '에', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [6, 7, 8, 9, 22, 23, 24, 57, 58, 65, 84, 100, 101, 105, 106, 107, 110, 111], 'mask_label': ['▁주', '한', '미', '군은', '▁그', '쳤다', '.', '▁관계', '가', '▁그러나', '▁대통령', '▁재', '선에', '▁또한', '▁임', '기', '▁터', '진']}\n",
            "enc_token: [5, 141, 867, 51, 5148, 4178, 6, 6, 6, 6, 443, 3640, 3917, 3636, 1083, 125, 847, 859, 209, 3909, 38, 189, 6, 6, 6, 276, 338, 3642, 4055, 36, 2649, 42, 3830, 550, 50, 786, 2408, 9, 128, 3993, 3683, 969, 3596, 4121, 191, 3604, 2995, 3625, 125, 3662, 27, 3946, 3604, 410, 3607, 2017, 54, 4615, 1600, 29, 3688, 3332, 43, 3599, 4, 6, 37, 3290, 243, 2630, 3708, 42, 3892, 636, 10, 42, 3892, 73, 3771, 1579, 3624, 1827, 1640, 3625, 6, 822, 10, 41, 3683, 1547, 194, 4044, 3681, 1169, 3803, 958, 113, 3596, 3944, 875, 6, 6, 1579, 31, 3599, 6180, 6, 6, 150, 329, 6, 6, 1302, 3601, 26, 2986, 3733, 1323, 3232, 636, 9, 751, 1640, 3625, 2219, 779, 3600, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 0\n",
            "label_mlm: [   0    0    0    0    0    0   37 3612 3686  941    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0   13 1523 3599    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0  704 3608    0    0    0    0    0    0  330    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  663    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0  174 2087    0    0    0  276  273 3614    0    0  870 3713\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', '▁밴', '스', '▁국', '무', '장', '관을', '▁조', '문', '사', '절', '로', '▁파견', '했다', '.', '[MASK]', '[MASK]', '[MASK]', '▁군사', '[MASK]', '[MASK]', '▁5', '.', '17', '▁쿠', '데', '타', '에', '▁대해', '▁초기', '에는', '▁강', '하게', '[MASK]', '[MASK]', '[MASK]', '▁미국', '[MASK]', '[MASK]', '▁신', '군', '부를', '▁설', '득', '하는데', ',', '▁한', '계가', '▁있었고', '▁결국', '▁', '묵', '인', '하는', '▁', '듯', '한', '▁태', '도를', '▁보이', '게', '▁', '됐다', '.', '[SEP]', '▁퇴', '임', '▁이후', '▁민간', '▁자', '원을', '▁적극', '▁활용', '한', '썹', '숙', '촐', '▁기', '구', '인', '▁카', '터', '▁재', '단을', '▁설립', '한', '▁뒤', '▁민주', '주의', '▁실', '현', '을', '[MASK]', '▁제', '▁3', '세', '계의', '▁선거', '▁감', '시', '[MASK]', '▁및', '▁기', '니', '▁벌', '레', '에', '▁의한', '▁드', '라', '쿤', '쿠', '르', '스', '▁질', '병', '▁방', '재', '를', '▁위해', '▁힘', '썼', '다', '.', '▁미국의', '▁빈', '곤', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [15, 16, 17, 19, 20, 33, 34, 35, 37, 38, 74, 75, 76, 92, 100, 116, 117, 118], 'mask_label': ['▁12', '·', '12', '▁반란', '과', '▁비난', '했으나', ',', '▁정부', '가', '▁비', '영', '리', '▁위해', '▁활동', '▁방', '재', '를']}\n",
            "enc_token: [5, 1228, 3626, 79, 3725, 3651, 1657, 53, 3697, 3620, 3931, 3603, 2338, 31, 3599, 6, 6, 6, 1250, 6, 6, 94, 3599, 1695, 927, 3736, 3732, 3600, 433, 1348, 66, 139, 173, 6, 6, 6, 243, 6, 6, 90, 3722, 1191, 178, 4059, 1294, 3604, 34, 2681, 2492, 875, 3596, 4502, 3628, 38, 3596, 4360, 3612, 227, 701, 3052, 3669, 3596, 1027, 3599, 4, 1382, 3773, 165, 3174, 40, 928, 2929, 2523, 3612, 6187, 4143, 5670, 24, 3653, 3628, 207, 3714, 174, 1574, 686, 3612, 339, 1114, 238, 158, 3756, 3607, 6, 30, 49, 3692, 1654, 822, 209, 3623, 6, 228, 24, 3733, 813, 3740, 3600, 1332, 311, 3635, 4956, 3937, 3699, 3626, 761, 3886, 95, 3729, 3624, 231, 947, 4437, 3598, 3599, 679, 1412, 4234, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 1\n",
            "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0  196 3873 1335    0 2342 3644    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0 3560 1003 3604    0  513 3608    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0   77 3715 3622    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0  231    0    0    0    0    0\n",
            "    0    0  375    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0   95 3729 3624    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', '상을', '▁거부', '하면서', '▁사', '태', '의', '▁위', '기를', '▁초', '래', '한', '▁인물', '▁및', '[MASK]', '[MASK]', '▁직접', '▁만나', '▁분', '쟁', '의', '▁원', '인을', '▁근', '본', '적으로', '▁해결', '하기', '▁위해', '▁힘', '썼', '다', '.', '▁이', '▁과정에서', '▁미국', '[MASK]', '[MASK]', '▁갈', '등', '을', '▁보', '이기도', '▁했지만', ',', '▁전', '직', '▁대통령', '의', '▁권', '한', '과', '▁재', '야', '▁유명', '▁인사', '들의', '▁컴', '냥', '▁해결', '해', '▁나', '갔다', '.', '[SEP]', '▁카', '터', '는', '▁카', '터', '▁행정', '부', '[MASK]', '▁미국', '이', '▁북', '핵', '▁위', '기', ',', '▁코', '소', '보', '▁전쟁', ',', '[MASK]', '[MASK]', '▁전쟁', '과', '▁같이', '▁미국', '이', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁최', '후', '로', '▁선택', '하는', '▁전통', '적', '▁사고', '를', '▁버', '리고', '▁군사', '적', '▁행', '동을', '▁선', '행', '하는', '▁행', '위에', '▁대해', '▁깊', '은', '▁유', '감을', '▁표시', '[MASK]', '▁미국의', '▁군사', '적', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [14, 15, 36, 37, 49, 50, 51, 57, 58, 72, 85, 86, 92, 93, 94, 95, 122, 126], 'mask_label': ['▁단', '체를', '▁행정', '부와', '▁권', '한', '과', '▁활약', '으로', '▁이후', '▁이', '라크', '▁군사', '적', '▁행', '동을', '▁하며', '▁활동']}\n",
            "enc_token: [5, 460, 2324, 421, 15, 3800, 3601, 45, 333, 192, 3808, 3612, 1178, 228, 6, 6, 1069, 2142, 147, 3972, 3601, 129, 1171, 387, 3759, 127, 2317, 167, 231, 947, 4437, 3598, 3599, 8, 2208, 243, 6, 6, 742, 3709, 3607, 47, 1304, 3379, 3604, 25, 3802, 663, 3601, 476, 3612, 3644, 174, 3775, 939, 3329, 247, 993, 4465, 2317, 3645, 58, 1133, 3599, 4, 207, 3714, 3602, 207, 3714, 895, 3638, 6, 243, 3597, 251, 4166, 45, 3614, 3604, 258, 3688, 3672, 506, 3604, 6, 6, 506, 3644, 733, 243, 3597, 6, 6, 6, 6, 130, 3706, 3603, 1715, 38, 1306, 3657, 1646, 3624, 407, 999, 1250, 3657, 236, 1629, 57, 3752, 38, 236, 1157, 433, 1910, 3613, 46, 2196, 2466, 6, 679, 1250, 3657, 6, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 0\n",
            "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  164 1396    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0  895 2576    0    0    0    0\n",
            "    0    0    0    0    0    0    0  476 3612 3644    0    0    0    0\n",
            "    0 1102    9    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0  165    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    8 3553    0    0    0    0    0 1250 3657  236 1629    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0 1368    0    0    0\n",
            "  375    0]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXSv7RuC2KF7"
      },
      "source": [
        "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
        "    \"\"\"\n",
        "    학습에 필요한 데이터를 로드\n",
        "    :param vocab: vocab\n",
        "    :param filename: 전처리된 json 파일\n",
        "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
        "    :param count: 데이터 수 제한 (None이면 전체)\n",
        "    :return enc_tokens: encoder inputs\n",
        "    :return segments: segment inputs\n",
        "    :return labels_nsp: nsp labels\n",
        "    :return labels_mlm: mlm labels\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            total += 1\n",
        "            # 데이터 수 제한\n",
        "            if count is not None and count <= total:\n",
        "                break\n",
        "    \n",
        "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
        "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
        "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "\n",
        "    with open(filename, \"r\") as f:\n",
        "        for i, line in enumerate(tqdm(f, total=total)):\n",
        "            if total <= i:\n",
        "                print(\"data load early stop\", total, i)\n",
        "                break\n",
        "            data = json.loads(line)\n",
        "            # encoder token\n",
        "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
        "            enc_token += [0] * (n_seq - len(enc_token))\n",
        "            # segment\n",
        "            segment = data[\"segment\"]\n",
        "            segment += [0] * (n_seq - len(segment))\n",
        "            # nsp label\n",
        "            label_nsp = data[\"is_next\"]\n",
        "            # mlm label\n",
        "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
        "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
        "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
        "            label_mlm[mask_idx] = mask_label\n",
        "\n",
        "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
        "\n",
        "            enc_tokens[i] = enc_token\n",
        "            segments[i] = segment\n",
        "            labels_nsp[i] = label_nsp\n",
        "            labels_mlm[i] = label_mlm\n",
        "\n",
        "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6fd8d329d2d54a558343e7d3e557ced4",
            "1c927d0887034dfb8fe5afde7b7568a0",
            "93b2e020e00247db9e8c53c8b6ce1055",
            "cea0f3a0229849d28f7bb580f4e1fda7",
            "21de7b2409d445f9adf06949e624bc3b",
            "0ca3cb7da39345e28902164652159c57",
            "af4b3f1de82744e3888ae8750b45160b",
            "d1d270bbe9dd4e00bfc089fc7bd8cf47"
          ]
        },
        "id": "jWsR5Dtw2Mkq",
        "outputId": "5e71c81f-f2aa-4eff-bc14-1b864256702e"
      },
      "source": [
        "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fd8d329d2d54a558343e7d3e557ced4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=128000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "data load early stop 128000 128000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4XHNlf32PEd",
        "outputId": "6077d9dc-9c8f-4d0c-84e4-6e798924c214"
      },
      "source": [
        "# 처음과 마지막 확인\n",
        "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(memmap([   5,   10, 1605, 3599, 1755, 3630,   41, 3644,  830, 3624, 1135,\n",
              "           52, 3599,   13,   81,   87, 1501, 2247,   25, 3779, 3873, 3667,\n",
              "         3631, 3813, 3873, 4196, 3636, 3779, 3601,  249, 3725, 1232,   33,\n",
              "           52, 3599,    6,    6,    6, 6322, 2780,   14, 1509,  168, 3877,\n",
              "          414,  165, 1697, 4290, 3873, 3703, 3683,  593,   21, 5007,  399,\n",
              "         1927, 3607,    6,    6,    6,    6,    6,    6,  103, 4313, 4290,\n",
              "          613, 3638, 3718,   98, 3878, 3656,  256, 2543,  309,  337, 3735,\n",
              "          181, 3616, 3603,  489,  376, 3599,    4,    6,    6,  207, 3714,\n",
              "            6, 1042,  103, 3610, 3686, 3718,    6,    6,   37, 3418,  416,\n",
              "          810, 3666, 3625,  131, 3662,    7, 3629,  203,  241, 3602, 1114,\n",
              "         3724,  788,  243,    6,    6,    6,  663, 1647, 3682, 3682, 3625,\n",
              "          203, 3008, 3625, 3616,   16, 3599,    4], dtype=int32),\n",
              " memmap([   5, 3676,  848, 3784, 1931,   58, 3676,  416, 2316, 3619, 3625,\n",
              "         3617, 3744, 4335,   12, 3625, 3616,  175, 3662,    7, 3629,  203,\n",
              "            6,    6,    6,    6,    6,    6,  143, 3625, 3616,  131, 3662,\n",
              "          342, 3629, 3616, 3602,  176,  334,  829, 1115, 3665,    6,    6,\n",
              "         3451, 1633,  375,  671, 1644, 3608,  547, 3423,  765,  815, 3604,\n",
              "            6,    6,    6, 2375, 3608, 3604,  532, 2589, 3599,    4,  307,\n",
              "          323,    6,  321, 3611,  622,  122, 3725, 3620, 3627, 3837, 3608,\n",
              "            6,  176,  268, 4082,   94,  567, 4014, 3617, 7474, 3616, 3830,\n",
              "           66, 3590,  307,  192, 1272,  158, 3788,  353, 3599,  202,  316,\n",
              "         3600,  176,   10,  323,  476, 3663, 1329,  605,  238, 3631, 2470,\n",
              "         3604, 1939,  106, 3627,   13,    6,    6, 1128,   48,    6,    6,\n",
              "          848, 3784, 3833,    8, 3637, 2263,    4], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
              " 0,\n",
              " 1,\n",
              " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,  479, 3652, 3625,  243,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,  813,   17, 3599,  307,  587,  931,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,   18, 3686,    0,    0,\n",
              "         3324,    0,    0,    0,    0,    0,  207, 3714,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,   49, 3632,  796,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
              " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          578, 3652, 3625, 3617, 4148, 3665,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0, 1381, 4148,\n",
              "         3451,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          752, 3608, 3604,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0, 2143,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          347,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,  162,  490,    0,    0,   28, 3599,\n",
              "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IBYwKq12QeS"
      },
      "source": [
        "def get_pad_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    pad mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: pad mask (pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
        "    mask = tf.expand_dims(mask, axis=1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_ahead_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    ahead mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    n_seq = tf.shape(tokens)[1]\n",
        "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
        "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
        "    pad_mask = get_pad_mask(tokens, i_pad)\n",
        "    mask = tf.maximum(ahead_mask, pad_mask)\n",
        "    return mask\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    gelu activation 함수\n",
        "    :param x: 입력 값\n",
        "    :return: gelu activation result\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
        "\n",
        "def kernel_initializer(stddev=0.02):\n",
        "    \"\"\"\n",
        "    parameter initializer 생성\n",
        "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
        "    \"\"\"\n",
        "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
        "\n",
        "\n",
        "def bias_initializer():\n",
        "    \"\"\"\n",
        "    bias initializer 생성\n",
        "    \"\"\"\n",
        "    return tf.zeros_initializer\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpPDJriU2aKJ"
      },
      "source": [
        "class Config(dict):\n",
        "    \"\"\"\n",
        "    json을 config 형태로 사용하기 위한 Class\n",
        "    :param dict: config dictionary\n",
        "    \"\"\"\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        \"\"\"\n",
        "        file에서 Config를 생성 함\n",
        "        :param file: filename\n",
        "        \"\"\"\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkNwvS1O2cbI"
      },
      "source": [
        "class SharedEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Weighed Shaed Embedding Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.n_vocab = config.n_vocab\n",
        "        self.d_model = config.d_model\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        shared weight 생성\n",
        "        :param input_shape: Tensor Shape (not used)\n",
        "        \"\"\"\n",
        "        with tf.name_scope(\"shared_embedding_weight\"):\n",
        "            self.shared_weights = self.add_weight(\n",
        "                \"weights\",\n",
        "                shape=[self.n_vocab, self.d_model],\n",
        "                initializer=kernel_initializer()\n",
        "            )\n",
        "\n",
        "    def call(self, inputs, mode=\"embedding\"):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: 입력\n",
        "        :param mode: 실행 모드\n",
        "        :return: embedding or linear 실행 결과\n",
        "        \"\"\"\n",
        "        # mode가 embedding일 경우 embedding lookup 실행\n",
        "        if mode == \"embedding\":\n",
        "            return self._embedding(inputs)\n",
        "        # mode가 linear일 경우 linear 실행\n",
        "        elif mode == \"linear\":\n",
        "            return self._linear(inputs)\n",
        "        # mode가 기타일 경우 오류 발생\n",
        "        else:\n",
        "            raise ValueError(f\"mode {mode} is not valid.\")\n",
        "    \n",
        "    def _embedding(self, inputs):\n",
        "        \"\"\"\n",
        "        embedding lookup\n",
        "        :param inputs: 입력\n",
        "        \"\"\"\n",
        "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
        "        return embed\n",
        "\n",
        "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
        "        \"\"\"\n",
        "        linear 실행\n",
        "        :param inputs: 입력\n",
        "        \"\"\"\n",
        "        n_batch = tf.shape(inputs)[0]\n",
        "        n_seq = tf.shape(inputs)[1]\n",
        "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
        "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
        "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
        "        return outputs\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSsABFPP2eaC",
        "outputId": "3b00385a-7900-4318-9ca1-de813747a6b3"
      },
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Positional Embedding Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"position_embedding\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: 입력\n",
        "        :return embed: positional embedding lookup 결과\n",
        "        \"\"\"\n",
        "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
        "        embed = self.embedding(position)\n",
        "        return embed\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B-dZJtP2gqt"
      },
      "source": [
        "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Scale Dot Product Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param Q: Q value\n",
        "        :param K: K value\n",
        "        :param V: V value\n",
        "        :param attn_mask: 실행 모드\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
        "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
        "        attn_scale = tf.math.divide(attn_score, scale)\n",
        "        attn_scale -= 1.e9 * attn_mask\n",
        "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
        "        attn_out = tf.matmul(attn_prob, V)\n",
        "        return attn_out\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tyLXsFE2jDe"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Multi Head Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"multi_head_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.d_model = config.d_model\n",
        "        self.n_head = config.n_head\n",
        "        self.d_head = config.d_head\n",
        "\n",
        "        # Q, K, V input dense layer\n",
        "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        # Scale Dot Product Attention class\n",
        "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
        "        # output dense layer\n",
        "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param Q: Q value\n",
        "        :param K: K value\n",
        "        :param V: V value\n",
        "        :param attn_mask: 실행 모드\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        # reshape Q, K, V, attn_mask\n",
        "        batch_size = tf.shape(Q)[0]\n",
        "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
        "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
        "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
        "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
        "        # transpose and liner\n",
        "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
        "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
        "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
        "\n",
        "        return attn_out\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5r9ilu2lGP",
        "outputId": "3833bf29-152a-4e1a-b5f4-f3bd76f40710"
      },
      "source": [
        "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Position Wise Feed Forward Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"feed_forward\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: inputs\n",
        "        :return ff_val: feed forward 실행 결과\n",
        "        \"\"\"\n",
        "        ff_val = self.W_2(self.W_1(inputs))\n",
        "        return ff_val\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3YtDYqi2m7g"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Encoder Layer Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"encoder_layer\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.self_attention = MultiHeadAttention(config)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "\n",
        "        self.ffn = PositionWiseFeedForward(config)\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        " \n",
        "    def call(self, enc_embed, self_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
        "        :param self_mask: enc_tokens의 pad mask\n",
        "        :return enc_out: EncoderLayer 실행 결과\n",
        "        \"\"\"\n",
        "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
        "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
        "\n",
        "        ffn_val = self.ffn(norm1_val)\n",
        "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
        "\n",
        "        return enc_out\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPIXqgac2opX"
      },
      "source": [
        "class BERT(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    BERT Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"bert\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.i_pad = config.i_pad\n",
        "        self.embedding = SharedEmbedding(config)\n",
        "        self.position = PositionalEmbedding(config)\n",
        "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "        \n",
        "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: (enc_tokens, segments)\n",
        "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
        "        \"\"\"\n",
        "        enc_tokens, segments = inputs\n",
        "\n",
        "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
        "\n",
        "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
        "\n",
        "        enc_out = self.dropout(enc_embed)\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
        "\n",
        "        logits_cls = enc_out[:,0]\n",
        "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
        "        return logits_cls, logits_lm\n",
        "    \n",
        "    def get_embedding(self, tokens, segments):\n",
        "        \"\"\"\n",
        "        token embedding, position embedding lookup\n",
        "        :param tokens: 입력 tokens\n",
        "        :param segments: 입력 segments\n",
        "        :return embed: embedding 결과\n",
        "        \"\"\"\n",
        "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
        "        embed = self.norm(embed)\n",
        "        return embed\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAlBkhMG2qnZ"
      },
      "source": [
        "# Encoder Layer class 정의\n",
        "class PooledOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        " \n",
        "    def call(self, inputs):\n",
        "        outputs = self.dense1(inputs)\n",
        "        outputs = self.dense2(outputs)\n",
        "        return outputs\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2AV306k2tg3"
      },
      "source": [
        "def build_model_pre_train(config):\n",
        "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
        "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
        "\n",
        "    bert = BERT(config)\n",
        "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
        "\n",
        "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
        "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
        "\n",
        "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
        "\n",
        "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
        "    return model\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb2sunJZ2vF6",
        "outputId": "9e259838-f185-4be9-e0ee-8f1fdce93558"
      },
      "source": [
        "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
        "config.n_vocab = len(vocab)\n",
        "config.i_pad = vocab.pad_id()\n",
        "config"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'d_ff': 1024,\n",
              " 'd_head': 64,\n",
              " 'd_model': 256,\n",
              " 'dropout': 0.1,\n",
              " 'i_pad': 0,\n",
              " 'layernorm_epsilon': 0.001,\n",
              " 'n_head': 4,\n",
              " 'n_layer': 3,\n",
              " 'n_seq': 256,\n",
              " 'n_vocab': 8007}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wr9WOLN2wto",
        "outputId": "cd622729-0032-4baa-da66-80eb56a5dd67"
      },
      "source": [
        "n_seq = 10\n",
        "\n",
        "# make test inputs\n",
        "enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
        "segments = np.random.randint(0, 2, (10, n_seq))\n",
        "labels_nsp = np.random.randint(0, 2, (10,))\n",
        "labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
        "\n",
        "test_model = build_model_pre_train(config)\n",
        "test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
        "\n",
        "# test model fit\n",
        "test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2/2 [==============================] - 17s 15ms/step - loss: 9.7573 - nsp_loss: 0.7075 - mlm_loss: 9.0499 - nsp_acc: 0.6667 - mlm_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.6211 - nsp_loss: 0.6080 - mlm_loss: 8.0131 - nsp_acc: 0.8667 - mlm_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe780126a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olJzECMX2zCi"
      },
      "source": [
        "def lm_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    loss 계산 함수\n",
        "    :param y_true: 정답 (bs, n_seq)\n",
        "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    \"\"\"\n",
        "    # loss 계산\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴\n",
        "\n",
        "\n",
        "def lm_acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    acc 계산 함수\n",
        "    :param y_true: 정답 (bs, n_seq)\n",
        "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    \"\"\"\n",
        "    # 정답 여부 확인\n",
        "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
        "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
        "    matches *= mask\n",
        "    # 정확도 계산\n",
        "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
        "    return accuracy\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc5abWVs22hF"
      },
      "source": [
        "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"\n",
        "    CosineSchedule Class\n",
        "    \"\"\"\n",
        "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param train_steps: 학습 step 총 합\n",
        "        :param warmup_steps: warmup steps\n",
        "        :param max_lr: 최대 learning rate\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert 0 < warmup_steps < train_steps\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.train_steps = train_steps\n",
        "        self.max_lr = max_lr\n",
        "\n",
        "    def __call__(self, step_num):\n",
        "        \"\"\"\n",
        "        learning rate 계산\n",
        "        :param step_num: 현재 step number\n",
        "        :retrun: 계산된 learning rate\n",
        "        \"\"\"\n",
        "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
        "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
        "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
        "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
        "        return (state * lr1 + (1 - state) * lr2) * self.max_lr\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "nF2bcNG724Hu",
        "outputId": "b675345d-1e3e-47f5-e483-af7c6f329c53"
      },
      "source": [
        "# compute lr \n",
        "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
        "lrs = []\n",
        "for step_num in range(4000):\n",
        "    lrs.append(test_schedule(float(step_num)).numpy())\n",
        "\n",
        "# draw\n",
        "plt.plot(lrs, 'r-', label='learning_rate')\n",
        "plt.xlabel('Step')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5CTWAje25-k",
        "outputId": "b8b11088-50ba-4fa1-a2fb-68dece4ef724"
      },
      "source": [
        "# 모델 생성\n",
        "pre_train_model = build_model_pre_train(config)\n",
        "pre_train_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segments (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n",
            "                                                                 segments[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n",
            "==================================================================================================\n",
            "Total params: 4,551,936\n",
            "Trainable params: 4,551,936\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737eoff427iO",
        "outputId": "7df7ad55-d1c9-4f31-a91c-d9ce12826c62"
      },
      "source": [
        "epochs = 3\n",
        "batch_size = 64\n",
        "\n",
        "# optimizer\n",
        "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
        "print(\"train_steps:\", train_steps)\n",
        "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# compile\n",
        "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_steps: 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXEVrU6z29LX",
        "outputId": "90b3c4bd-ddd8-4e95-ab33-a4f4d11ea02c"
      },
      "source": [
        "# save weights callback\n",
        "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
        "# train\n",
        "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2000/2000 [==============================] - 206s 102ms/step - loss: 20.1986 - nsp_loss: 0.6592 - mlm_loss: 19.5394 - nsp_acc: 0.5753 - mlm_lm_acc: 0.1048\n",
            "\n",
            "Epoch 00001: mlm_lm_acc improved from -inf to 0.11575, saving model to /content/drive/MyDrive/DL_Study/AIFFEL/19_Bert//models/bert_pre_train.hdf5\n",
            "Epoch 2/3\n",
            "2000/2000 [==============================] - 203s 102ms/step - loss: 17.3942 - nsp_loss: 0.6186 - mlm_loss: 16.7756 - nsp_acc: 0.6242 - mlm_lm_acc: 0.1304\n",
            "\n",
            "Epoch 00002: mlm_lm_acc improved from 0.11575 to 0.13235, saving model to /content/drive/MyDrive/DL_Study/AIFFEL/19_Bert//models/bert_pre_train.hdf5\n",
            "Epoch 3/3\n",
            "2000/2000 [==============================] - 203s 102ms/step - loss: 16.8734 - nsp_loss: 0.6103 - mlm_loss: 16.2631 - nsp_acc: 0.6385 - mlm_lm_acc: 0.1371\n",
            "\n",
            "Epoch 00003: mlm_lm_acc improved from 0.13235 to 0.13739, saving model to /content/drive/MyDrive/DL_Study/AIFFEL/19_Bert//models/bert_pre_train.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VnOkUOUr2-lh",
        "outputId": "e7797490-533b-4a81-cb07-81fd2c89e735"
      },
      "source": [
        "# training result\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
        "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
        "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYWk7GOv3AWB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}