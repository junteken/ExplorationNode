{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnKssOozSZzh"
   },
   "source": [
    "17-6. 프로젝트 - Movielens 영화 SBR\n",
    "이번에도 우리는 Movielens 1M Dataset을 기반으로, Session based Recommendation 시스템을 제작해 보겠습니다.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "1) wget으로 데이터 다운로드\n",
    "$ wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "\n",
    "2) 다운받은 데이터를 작업디렉토리로 이동\n",
    "$ mv ml-1m.zip ~/aiffel/yoochoose-data\n",
    "\n",
    "3) 압축 해제\n",
    "$ cd ~/aiffel/yoochoose-data && unzip ml-1m.zip\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdAcZnOS7_Bv",
    "outputId": "7addf47d-bf80-4ff8-a30d-e0b27dd5ced2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "IkC5GPyoSQ3e",
    "outputId": "a6e49cef-dcba-4704-9e65-f823e1746dc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>997454429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>997454486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating       Time\n",
       "31            1    3186       4  978300019\n",
       "22            1    1270       5  978300055\n",
       "27            1    1721       4  978300055\n",
       "37            1    1022       5  978300055\n",
       "24            1    2340       3  978300103\n",
       "...         ...     ...     ...        ...\n",
       "1000019    6040    2917       4  997454429\n",
       "999988     6040    1921       4  997454464\n",
       "1000172    6040    1784       3  997454464\n",
       "1000167    6040     161       3  997454486\n",
       "1000042    6040    1221       4  998315055\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "data_path = '/content/drive/MyDrive/DL_Study/AIFFEL/yoochoose/ml-1m/'\n",
    "\n",
    "train_path = data_path + 'ratings.dat'\n",
    "\n",
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep='::', header=None, usecols=[0, 1, 2, 3], dtype={0: np.int32, 1: np.int32, 2: np.int32}, nrows=nrows)\n",
    "    data.columns = ['UserId', 'ItemId', 'Rating', 'Time']\n",
    "    return data\n",
    "\n",
    "data = load_data(train_path, None)\n",
    "data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PbtrfHySvwY"
   },
   "source": [
    "여기서 이전 실습내역과 가장 크게 다른 부분은 바로 SessionID 대신 UserID 항목이 들어갔다는 점입니다. 이 데이터셋은 명확한 1회 세션의 SessionID를 포함하지 않고 있습니다. 그래서 이번에는 UserID가 SessionID 역할을 해야 합니다.\n",
    "\n",
    "Rating 정보가 포함되어 있습니다. 이전 실습내역에서는 이런 항목이 포함되어 있지 않았으므로, 무시하고 제외할 수 있습니다. 하지만, 직전에 봤던 영화가 맘에 들었는지 여부가 비슷한 영화를 더 고르게 하는 것과 상관이 있을 수도 있습니다. 아울러, Rating이 낮은 데이터를 어떻게 처리할지도 고민해야 합니다.\n",
    "\n",
    "Time 항목에는 UTC time 가 포함되어, 1970년 1월 1일부터 경과된 초단위 시간이 기재되어 있습니다.\n",
    "\n",
    "위와 같은 정보를 바탕으로 오늘의 실습과정과 유사한 프로젝트 과정을 진행해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55RVmbwB8pHG"
   },
   "source": [
    "\n",
    "Step 1. 데이터의 전처리\n",
    "위와 같이 간단히 구성해 본 데이터셋을 꼼꼼이 살펴보면서 항목별 기본분석, session length, session time, cleaning 등의 작업을 진행합니다.\n",
    "특히, 이 데이터셋에서는 Session이 아닌 UserID 단위로 데이터가 생성되어 있으므로, 이를 Session 단위로 어떻게 해석할지에 주의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTG2-JFb8wWd",
    "outputId": "ba2a22d3-dd43-4a2f-95f4-7a7b5135bc0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId\n",
       "1        53\n",
       "2       129\n",
       "3        51\n",
       "4        21\n",
       "5       198\n",
       "       ... \n",
       "6036    888\n",
       "6037    202\n",
       "6038     20\n",
       "6039    123\n",
       "6040    341\n",
       "Length: 6040, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_length = data.groupby('UserId').size()\n",
    "session_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4JdNALf9JbW",
    "outputId": "684d2213-ec25-44ca-fdf3-e83d4fefe5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99퍼센트의 데이터가 모여있는 user가 영화를 못 횟수 = 906.659999999998\n",
      "session_length의 최대값은 = 2314\n"
     ]
    }
   ],
   "source": [
    "print('99퍼센트의 데이터가 모여있는 user가 영화를 못 횟수 = {count}'.format(count = session_length.quantile(0.99)) )\n",
    "print('session_length의 최대값은 = {max}'.format(max= session_length.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l35q8Ba7AEt8"
   },
   "source": [
    "90퍼센트의 user가 906번 정도의 item을 소비한다. 모델의 정확도를 높이기 위해 906개 이상은 버리는걸로 전처리 하는걸로~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "aN8Jpn-K-atq",
    "outputId": "f818f106-c9d8-41e3-8a56-533ccf229cb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>997454429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>997454486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999611 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating       Time\n",
       "31            1    3186       4  978300019\n",
       "22            1    1270       5  978300055\n",
       "27            1    1721       4  978300055\n",
       "37            1    1022       5  978300055\n",
       "24            1    2340       3  978300103\n",
       "...         ...     ...     ...        ...\n",
       "1000019    6040    2917       4  997454429\n",
       "999988     6040    1921       4  997454464\n",
       "1000172    6040    1784       3  997454464\n",
       "1000167    6040     161       3  997454486\n",
       "1000042    6040    1221       4  998315055\n",
       "\n",
       "[999611 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# short_session을 제거한 다음 unpopular item을 제거하면 다시 길이가 1인 session이 생길 수 있습니다.\n",
    "# 이를 위해 반복문을 통해 지속적으로 제거 합니다.\n",
    "def cleanse_recursive(data: pd.DataFrame, shortest, least_click) -> pd.DataFrame:\n",
    "    while True:\n",
    "        before_len = len(data)\n",
    "        data = cleanse_short_session(data, shortest)\n",
    "        data = cleanse_unpopular_item(data, least_click)\n",
    "        after_len = len(data)\n",
    "        if before_len == after_len:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_short_session(data: pd.DataFrame, shortest):\n",
    "    session_len = data.groupby('UserId').size()\n",
    "    session_use = session_len[session_len >= shortest].index\n",
    "    data = data[data['UserId'].isin(session_use)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_unpopular_item(data: pd.DataFrame, least_click):\n",
    "    item_popular = data.groupby('ItemId').size()\n",
    "    item_use = item_popular[item_popular >= least_click].index\n",
    "    data = data[data['ItemId'].isin(item_use)]\n",
    "    return data\n",
    "\n",
    "data = cleanse_recursive(data, shortest=2, least_click=5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrULu7z_8wrt"
   },
   "source": [
    "\n",
    "Step 2. 미니 배치의 구성\n",
    "실습코드 내역을 참고하여 데이터셋과 미니 배치를 구성해 봅시다. Session-Parallel Mini-Batch의 개념에 따라, 학습 속도의 저하가 최소화될 수 있도록 구성합니다.\n",
    "단, 위 Step 1에서 Session 단위를 어떻게 정의했느냐에 따라서 Session-Parallel Mini-Batch이 굳이 필요하지 않을 수도 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbOnMA6RE_ts"
   },
   "outputs": [],
   "source": [
    "# day -> second 변환 함수\n",
    "def day_to_time(n_days: int):\n",
    "  return  60*60*24*n_days\n",
    "\n",
    "def split_by_date(data: pd.DataFrame, n_days: int):\n",
    "    final_time = data['Time'].max()\n",
    "    session_last_time = data.groupby('UserId')['Time'].max()\n",
    "    session_in_train = session_last_time[session_last_time < final_time - day_to_time(n_days)].index\n",
    "    session_in_test = session_last_time[session_last_time >= final_time - day_to_time(n_days)].index\n",
    "\n",
    "    before_date = data[data['UserId'].isin(session_in_train)]\n",
    "    after_date = data[data['UserId'].isin(session_in_test)]\n",
    "    after_date = after_date[after_date['ItemId'].isin(before_date['ItemId'])]\n",
    "    return before_date, after_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxL0pgN_Fm30"
   },
   "outputs": [],
   "source": [
    "tr, test = split_by_date(data, n_days=1)\n",
    "tr, val = split_by_date(tr, n_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EZyL_HdIC2t",
    "outputId": "6b4dd330-a5c5-4c99-b743-49bc0887802b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train Set Stats Info\n",
      "\t Events: 992526\n",
      "\t UserId: 6026\n",
      "\t Items: 3416\n",
      "\t First Time : 956703932\n",
      "\t Last Time : 1046208129\n",
      "\n",
      "* valid Set Stats Info\n",
      "\t Events: 3911\n",
      "\t UserId: 7\n",
      "\t Items: 1784\n",
      "\t First Time : 958845475\n",
      "\t Last Time : 1046355727\n",
      "\n",
      "* test Set Stats Info\n",
      "\t Events: 3174\n",
      "\t UserId: 7\n",
      "\t Items: 1488\n",
      "\t First Time : 957179713\n",
      "\t Last Time : 1046454590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data에 대한 정보를 살펴봅니다.\n",
    "def stats_info(data: pd.DataFrame, status: str):\n",
    "    print(f'* {status} Set Stats Info\\n'\n",
    "          f'\\t Events: {len(data)}\\n'\n",
    "          f'\\t UserId: {data[\"UserId\"].nunique()}\\n'\n",
    "          f'\\t Items: {data[\"ItemId\"].nunique()}\\n'\n",
    "          f'\\t First Time : {data[\"Time\"].min()}\\n'\n",
    "          f'\\t Last Time : {data[\"Time\"].max()}\\n')\n",
    "    \n",
    "stats_info(tr, 'train')\n",
    "stats_info(val, 'valid')\n",
    "stats_info(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMW0gnvUIVfC"
   },
   "outputs": [],
   "source": [
    "# train set에 없는 아이템이 val, test기간에 생길 수 있으므로 train data를 기준으로 인덱싱합니다.\n",
    "id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n",
    "\n",
    "def indexing(df, id2idx):\n",
    "    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))  # id2idx에 없는 아이템은 모르는 값(-1) 처리 해줍니다.\n",
    "    return df\n",
    "\n",
    "tr = indexing(tr, id2idx)\n",
    "val = indexing(val, id2idx)\n",
    "test = indexing(test, id2idx)\n",
    "\n",
    "import pathlib\n",
    "\n",
    "save_path = data_path + 'processed/'\n",
    "\n",
    "pathlib.Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "# save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tr.to_pickle(save_path + 'train.pkl')\n",
    "val.to_pickle(save_path + 'valid.pkl')\n",
    "test.to_pickle(save_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6iHqsMhIbxD"
   },
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.click_offsets = self.get_click_offsets()\n",
    "        self.session_idx = np.arange(self.df['UserId'].nunique())  # indexing to SessionId\n",
    "\n",
    "    def get_click_offsets(self):\n",
    "        \"\"\"\n",
    "        Return the indexes of the first click of each session IDs,\n",
    "        \"\"\"\n",
    "        offsets = np.zeros(self.df['UserId'].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby('UserId').size().cumsum()\n",
    "        return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CoG7pItFIjdQ",
    "outputId": "4945c98a-1592-4a0e-e342-2237b2eef59d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,     53,    182, ..., 992062, 992185, 992526], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset = SessionDataset(tr)\n",
    "tr_dataset.df.head(10)\n",
    "tr_dataset.click_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "klLuAANzIqh5",
    "outputId": "2cace305-e144-4285-c5fc-150a343a72f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1836</td>\n",
       "      <td>5</td>\n",
       "      <td>978300172</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1207</td>\n",
       "      <td>4</td>\n",
       "      <td>978300719</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3</td>\n",
       "      <td>978300760</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>978300760</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>978301368</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>4</td>\n",
       "      <td>978301398</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>2692</td>\n",
       "      <td>4</td>\n",
       "      <td>978301570</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserId  ItemId  Rating       Time  item_idx\n",
       "31       1    3186       4  978300019         0\n",
       "22       1    1270       5  978300055         1\n",
       "27       1    1721       4  978300055         2\n",
       "37       1    1022       5  978300055         3\n",
       "24       1    2340       3  978300103         4\n",
       "36       1    1836       5  978300172         5\n",
       "3        1    3408       4  978300275         6\n",
       "7        1    2804       5  978300719         7\n",
       "47       1    1207       4  978300719         8\n",
       "0        1    1193       5  978300760         9\n",
       "21       1     720       3  978300760        10\n",
       "44       1     260       4  978300760        11\n",
       "9        1     919       4  978301368        12\n",
       "51       1     608       4  978301398        13\n",
       "43       1    2692       4  978301570        14"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SessionDataLoader:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: SessionDataset, batch_size=50):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
    "        Yields:\n",
    "            input (B,):  Item indices that will be encoded as one-hot vectors later.\n",
    "            target (B,): a Variable that stores the target item indices\n",
    "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        start, end, mask, last_session, finished = self.initialize()  # initialize 메소드에서 확인해주세요.\n",
    "        \"\"\"\n",
    "        start : Index Where Session Start\n",
    "        end : Index Where Session End\n",
    "        mask : indicator for the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        while not finished:\n",
    "            min_len = (end - start).min() - 1  # Shortest Length Among Sessions\n",
    "            for i in range(min_len):\n",
    "                # Build inputs & targets\n",
    "                inp = self.dataset.df['item_idx'].values[start + i]\n",
    "                target = self.dataset.df['item_idx'].values[start + i + 1]\n",
    "                yield inp, target, mask\n",
    "\n",
    "            start, end, mask, last_session, finished = self.update_status(start, end, min_len, last_session, finished)\n",
    "\n",
    "    def initialize(self):\n",
    "        first_iters = np.arange(self.batch_size)    # 첫 배치에 사용할 세션 Index를 가져옵니다.\n",
    "        last_session = self.batch_size - 1    # 마지막으로 다루고 있는 세션 Index를 저장해둡니다.\n",
    "        start = self.dataset.click_offsets[self.dataset.session_idx[first_iters]]       # data 상에서 session이 시작된 위치를 가져옵니다.\n",
    "        end = self.dataset.click_offsets[self.dataset.session_idx[first_iters] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n",
    "        mask = np.array([])   # session의 모든 아이템을 다 돌은 경우 mask에 추가해줄 것입니다.\n",
    "        finished = False         # data를 전부 돌았는지 기록하기 위한 변수입니다.\n",
    "        return start, end, mask, last_session, finished\n",
    "\n",
    "    def update_status(self, start: np.ndarray, end: np.ndarray, min_len: int, last_session: int, finished: bool):  \n",
    "        # 다음 배치 데이터를 생성하기 위해 상태를 update합니다.\n",
    "        \n",
    "        start += min_len   # __iter__에서 min_len 만큼 for문을 돌았으므로 start를 min_len 만큼 더해줍니다.\n",
    "        mask = np.arange(self.batch_size)[(end - start) == 1]  \n",
    "        # end는 다음 세션이 시작되는 위치인데 start와 한 칸 차이난다는 것은 session이 끝났다는 뜻입니다. mask에 기록해줍니다.\n",
    "\n",
    "        for i, idx in enumerate(mask, start=1):  # mask에 추가된 세션 개수만큼 새로운 세션을 돌것입니다.\n",
    "            new_session = last_session + i  \n",
    "            if new_session > self.dataset.session_idx[-1]:  # 만약 새로운 세션이 마지막 세션 index보다 크다면 모든 학습데이터를 돈 것입니다.\n",
    "                finished = True\n",
    "                break\n",
    "            # update the next starting/ending point\n",
    "            start[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session]]     # 종료된 세션 대신 새로운 세션의 시작점을 기록합니다.\n",
    "            end[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session] + 1]\n",
    "\n",
    "        last_session += len(mask)  # 마지막 세션의 위치를 기록해둡니다.\n",
    "        return start, end, mask, last_session, finished\n",
    "\n",
    "\n",
    "tr_data_loader = SessionDataLoader(tr_dataset, batch_size=4)\n",
    "tr_dataset.df.head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmhDnI5GI1Ng"
   },
   "outputs": [],
   "source": [
    "iter_ex = iter(tr_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JppGl1AyI3sE",
    "outputId": "98a0d416-1e49-474a-e59d-9eff5ee679b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Item Idx are : [ 0 53 65 54]\n",
      "Label Item Idx are :       [ 1 54 62 24]\n",
      "Previous Masked Input Idx are []\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, mask =  next(iter_ex)\n",
    "print(f'Model Input Item Idx are : {inputs}')\n",
    "print(f'Label Item Idx are : {\"\":5} {labels}')\n",
    "print(f'Previous Masked Input Idx are {mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scUT7OR9I95V"
   },
   "outputs": [],
   "source": [
    "def mrr_k(pred, truth: int, k: int):\n",
    "    indexing = np.where(pred[:k] == truth)[0]\n",
    "    if len(indexing) > 0:\n",
    "        return 1 / (indexing[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def recall_k(pred, truth: int, k: int) -> int:\n",
    "    answer = truth in pred[:k]\n",
    "    return int(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_4tybgtJAGU",
    "outputId": "0e892cf6-bcab-45ff-a972-630a2ff11fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(7, 1, 3416)]            0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(7, 50), (7, 50)]        520200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (7, 50)                   0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (7, 3416)                 174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GRU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_model(args):\n",
    "    inputs = Input(batch_shape=(args.batch_size, 1, args.num_items))\n",
    "    gru, _ = GRU(args.hsz, stateful=True, return_state=True, name='GRU')(inputs)\n",
    "    dropout = Dropout(args.drop_rate)(gru)\n",
    "    predictions = Dense(args.num_items, activation='softmax')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=[predictions])\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n",
    "        self.tr = tr\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.num_items = tr['ItemId'].nunique()\n",
    "        self.num_sessions = tr['UserId'].nunique()\n",
    "        self.batch_size = batch_size\n",
    "        self.hsz = hsz\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.k = k\n",
    "\n",
    "args = Args(tr, val, test, batch_size=7, hsz=50, drop_rate=0.1, lr=0.001, epochs=3, k=20)\n",
    "model = create_model(args)\n",
    "\n",
    "\n",
    "# train 셋으로 학습하면서 valid 셋으로 검증합니다.\n",
    "def train_model(model, args):\n",
    "    train_dataset = SessionDataset(args.tr)\n",
    "    train_loader = SessionDataLoader(train_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        total_step = len(args.tr) - args.tr['UserId'].nunique()\n",
    "        tr_loader = tqdm(train_loader, total=total_step // args.batch_size, desc='Train', mininterval=1)\n",
    "        for feat, target, mask in tr_loader:\n",
    "            reset_hidden_states(model, mask)  # 종료된 session은 hidden_state를 초기화합니다. 아래 메서드에서 확인해주세요.\n",
    "\n",
    "            input_ohe = to_categorical(feat, num_classes=args.num_items)\n",
    "            input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "            target_ohe = to_categorical(target, num_classes=args.num_items)\n",
    "\n",
    "            result = model.train_on_batch(input_ohe, target_ohe)\n",
    "            tr_loader.set_postfix(train_loss=result[0], accuracy = result[1])\n",
    "\n",
    "        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)  # valid set에 대해 검증합니다.\n",
    "\n",
    "        print(f\"\\t - Recall@{args.k} epoch {epoch}: {val_recall:3f}\")\n",
    "        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:3f}\\n\")\n",
    "\n",
    "\n",
    "def reset_hidden_states(model, mask):\n",
    "    gru_layer = model.get_layer(name='GRU')  # model에서 gru layer를 가져옵니다.\n",
    "    hidden_states = gru_layer.states[0].numpy()  # gru_layer의 parameter를 가져옵니다.\n",
    "    for elt in mask:  # mask된 인덱스 즉, 종료된 세션의 인덱스를 돌면서\n",
    "        hidden_states[elt, :] = 0  # parameter를 초기화 합니다.\n",
    "    gru_layer.reset_states(states=hidden_states)\n",
    "\n",
    "\n",
    "def get_metrics(data, model, args, k: int):  # valid셋과 test셋을 평가하는 코드입니다. \n",
    "                                             # train과 거의 같지만 mrr, recall을 구하는 라인이 있습니다.\n",
    "    dataset = SessionDataset(data)\n",
    "    loader = SessionDataLoader(dataset, batch_size=args.batch_size)\n",
    "    recall_list, mrr_list = [], []\n",
    "\n",
    "    total_step = len(data) - data['UserId'].nunique()\n",
    "    for inputs, label, mask in tqdm(loader, total=total_step // args.batch_size, desc='Evaluation', mininterval=1):\n",
    "        reset_hidden_states(model, mask)\n",
    "        input_ohe = to_categorical(inputs, num_classes=args.num_items)\n",
    "        input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "\n",
    "        pred = model.predict(input_ohe, batch_size=args.batch_size)\n",
    "        pred_arg = tf.argsort(pred, direction='DESCENDING')  # softmax 값이 큰 순서대로 sorting 합니다.\n",
    "\n",
    "        length = len(inputs)\n",
    "        recall_list.extend([recall_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "        mrr_list.extend([mrr_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "\n",
    "    recall, mrr = np.mean(recall_list), np.mean(mrr_list)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uP878LBlJTzY",
    "outputId": "6711d75f-caee-43cd-e381-2d2fa9e9e297"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████▉| 140662/140928 [39:54<00:04, 58.75it/s, accuracy=0, train_loss=6.39]\n",
      "Evaluation:  38%|███▊      | 211/557 [00:17<00:28, 12.13it/s]\n",
      "Train:   0%|          | 0/140928 [00:00<?, ?it/s, accuracy=0, train_loss=5.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 1: 0.348680\n",
      "\t - MRR@20    epoch 1: 0.102678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████▉| 140662/140928 [40:14<00:04, 58.25it/s, accuracy=0, train_loss=6.52]\n",
      "Evaluation:  38%|███▊      | 211/557 [00:16<00:27, 12.57it/s]\n",
      "Train:   0%|          | 0/140928 [00:00<?, ?it/s, accuracy=0, train_loss=5.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 2: 0.375762\n",
      "\t - MRR@20    epoch 2: 0.108584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████▉| 140662/140928 [40:39<00:04, 57.66it/s, accuracy=0, train_loss=6.1]\n",
      "Evaluation:  38%|███▊      | 211/557 [00:17<00:28, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 3: 0.375085\n",
      "\t - MRR@20    epoch 3: 0.111370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습 시간이 다소 오래 소요됩니다. (예상시간 1시간)\n",
    "train_model(model, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JPvV20IFALN"
   },
   "source": [
    "\n",
    "Step 3. 모델 구성\n",
    "이 부분도 실습코드 내역을 참고하여 다양하게 모델 구조를 시도해볼 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9Uy-r_GJDoM",
    "outputId": "9bd03b44-2a8d-4a9c-d3b0-7d7a0917cb5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  62%|██████▏   | 279/452 [00:23<00:14, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20: 0.242192\n",
      "\t - MRR@20: 0.067204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, args, test):\n",
    "    test_recall, test_mrr = get_metrics(test, model, args, 20)\n",
    "    print(f\"\\t - Recall@{args.k}: {test_recall:3f}\")\n",
    "    print(f\"\\t - MRR@{args.k}: {test_mrr:3f}\\n\")\n",
    "\n",
    "test_model(model, args, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54i2tTQbJD_u"
   },
   "source": [
    "\n",
    "Step 4. 모델 학습\n",
    "다양한 하이퍼파라미터를 변경해 보며 검증해 보도록 합니다. 실습코드에 언급되었던 Recall, MRR 등의 개념들도 함께 관리될 수 있도록 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_bC8iF6JFlW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRiT8_cpJGHG"
   },
   "source": [
    "\n",
    "Step 5. 모델 테스트\n",
    "미리 구성한 테스트셋을 바탕으로 Recall, MRR 을 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2At-bAufJG4J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq9JGhqcS2qT"
   },
   "source": [
    "루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "1. Movielens 데이터셋을 session based recommendation 관점으로 전처리하는 과정이 체계적으로 진행되었다.\n",
    "\n",
    "데이터셋의 면밀한 분석을 토대로 세션단위 정의 과정(길이분석, 시간분석)을 합리적으로 수행한 과정이 기술되었다.\n",
    "2. RNN 기반의 예측 모델이 정상적으로 구성되어 안정적으로 훈련이 진행되었다.\n",
    "\n",
    "적절한 epoch만큼의 학습이 진행되는 과정에서 train loss가 안정적으로 감소하고, validation 단계에서의 Recall, MRR이 개선되는 것이 확인된다.\n",
    "3. 세션정의, 모델구조, 하이퍼파라미터 등을 변경해서 실험하여 Recall, MRR 등의 변화추이를 관찰하였다.\n",
    "\n",
    "3가지 이상의 변화를 시도하고 그 실험결과를 체계적으로 분석하였다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7BBEGEBSwZK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "E17_Project.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
